# Kokoro TTS Add-on

> ğŸ§  Local Neural Text-to-Speech for Firefox â€” fast, private, offline.

> **Tested on a Xeon E3-1265L v3 (2013)** â€” Ran multiple TTS jobs in parallel with barely perceptible lag.  
> If it works on this, it'll fly on your machine.

---

## ğŸ” What is This?

Kokoro TTS is a browser extension that lets you convert selected or pasted text into natural-sounding speech â€” without needing an internet connection.  
It uses a lightweight Flask server and the Kokoro model running locally on your system.

- âœ… No accounts or logins
- âœ… No cloud APIs or telemetry
- âœ… No GPU required but helps a lot, if no usable GPU falls to using the CPU.

---

## ğŸš€ Features

- ğŸ™ï¸ Neural TTS with multiple voice options
- ğŸ”’ Offline-first & privacy-respecting
- ğŸ§Š Lightweight: Small 82M parameters
- ğŸ¥” Works on low-end CPUs
- ğŸŒ Linux, macOS, and Windows support
- ğŸ”Œ OpenAI-compatible API endpoint for integration with VibeVoice and other services
- ğŸ“¡ Real-time streaming support with SSE (Server-Sent Events)
- âš™ï¸ Configurable API endpoint for local or remote TTS services

---

## âš™ï¸ Installation

### 1. Download from Releases

Head to the [Releases Page](https://github.com/pinguy/kokoro-tts-addon/releases) and grab:

- `latest kokoro-tts-addon.xpi`
- `server.py`

### 2. Install the Add-on in Firefox

- Go to `about:addons`
- Click the gear icon â†’ `Install Add-on From File...`
- Select the `.xpi` you downloaded

### 3. Start the Local Server

#### macOS / Linux:
```bash
nohup python3 /path/to/server.py &
```

#### Windows:
Create a `.bat` file like this:
```bat
cd C:\path\to\server
start python server.py
```
Drop a shortcut to it in the Startup folder (`Win + R â†’ shell:startup`).

To install espeak-ng on Windows:
1. Go to [espeak-ng releases](https://github.com/espeak-ng/espeak-ng/releases)
2. Click on **Latest release**
3. Download the appropriate `*.msi` file (e.g. **espeak-ng-20191129-b702b03-x64.msi**)
4. Run the downloaded installer

For advanced configuration and usage on Windows, see the [official espeak-ng Windows guide](https://github.com/espeak-ng/espeak-ng/blob/master/docs/guide.md)

---

## ğŸ§ª How to Test

1. Visit `http://localhost:8000/health`  
2. You should see a simple â€œhealthyâ€ JSON response
3. Use the extension: paste text, pick a voice, click â€œGenerate Speechâ€ ğŸ‰

---

## ğŸ”Œ OpenAI API Integration & VibeVoice Support

The server now supports OpenAI-compatible API endpoints, allowing integration with services like VibeVoice!

### OpenAI-Compatible Endpoint

The server exposes `/v1/audio/speech` endpoint that accepts OpenAI-style requests:

```bash
curl -X POST "http://localhost:8000/v1/audio/speech" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "kokoro",
    "voice": "af_heart",
    "input": "Hello, this is a test!",
    "response_format": "wav",
    "speed": 1.0
  }' \
  --output speech.wav
```

### Streaming with SSE

For real-time streaming, add `stream_format: "sse"` to your request:

```bash
curl -X POST "http://localhost:8000/v1/audio/speech" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "kokoro",
    "voice": "af_heart",
    "input": "Hello, streaming audio!",
    "response_format": "pcm",
    "stream_format": "sse"
  }'
```

### Using with VibeVoice

To use an external VibeVoice API server:

1. Open the extension popup
2. Set the **API Endpoint** to your VibeVoice server URL (e.g., `http://127.0.0.1:8000`)
3. Enter your **API Key** if required
4. Check the **"Use OpenAI-compatible format"** checkbox
5. Select your text and generate speech!

The extension will automatically use the VibeVoice streaming format and handle SSE responses.

### Voice Mapping

The following OpenAI voice names are automatically mapped to Kokoro voices:
- `alloy` â†’ `af_alloy`
- `echo` â†’ `am_echo`
- `fable` â†’ `bm_fable`
- `onyx` â†’ `am_onyx`
- `nova` â†’ `af_nova`
- `shimmer` â†’ `af_sky`

---

## ğŸ“Œ Notes

- First-time run will download the model
- Make sure Python 3.8+ is installed and in PATH
- All processing is local â€” nothing leaves your machine (unless using external API endpoint)

---

## ğŸ§© Dependencies

Youâ€™ll need Python 3.8+ and `pip` installed. Most systems already have them.  
To install all required Python packages (including some optional extras for extended model usage), run:

```bash
python3 -m pip install --upgrade pip
pip install --upgrade pip setuptools
cat requirements.txt | xargs -n 1 pip3 install
pip3 install -U flask-cors
```

---

## ğŸ“„ License

Licensed under the [Apache License 2.0](LICENSE)

---

## â¤ï¸ Credits

Powered by the Kokoro TTS model

---

| Feature                                                          | Preview                                                                                 |
| ---------------------------------------------------------------- | --------------------------------------------------------------------------------------- |
| **Popup UI**: Select text, and this pops up.              | [![UI Preview](https://i.imgur.com/zXvETFV.png)](https://i.imgur.com/zXvETFV.png)       |
| **Playback in Action**: After clicking "Generate Speech"         | [![Playback Preview](https://i.imgur.com/STeXJ78.png)](https://i.imgur.com/STeXJ78.png) |
| **System Notifications**: Get notified when playback starts      | *(not pictured)*                                             |
| **Settings Panel**: configuration options         | [![Settings](https://i.imgur.com/wNOgrnZ.png)](https://i.imgur.com/wNOgrnZ.png)         |
| **Voice List**: Browse the models available                      | [![Voices](https://i.imgur.com/3fTutUR.png)](https://i.imgur.com/3fTutUR.png)           |
| **Accents Supported**: ğŸ‡ºğŸ‡¸ American English, ğŸ‡¬ğŸ‡§ British English, ğŸ‡ªğŸ‡¸ Spanish, ğŸ‡«ğŸ‡· French, ğŸ‡®ğŸ‡¹ Italian, ğŸ‡§ğŸ‡· Portuguese (BR), ğŸ‡®ğŸ‡³ Hindi, ğŸ‡¯ğŸ‡µ Japanese,  ğŸ‡¨ğŸ‡³ Mandarin Chines | [![Accents](https://i.imgur.com/lc7qgYN.png)](https://i.imgur.com/lc7qgYN.png)          |

---

# Video - Kokoro Text-to-Speech - Local on a Potato Vs Hugging Face 

[![Watch the video](https://img.youtube.com/vi/6AVZFwWllgU/hqdefault.jpg)](https://www.youtube.com/watch?v=6AVZFwWllgU)

*Comparison of offline using MKLDNN vs online generation using WASM/WebGPU.*

---
